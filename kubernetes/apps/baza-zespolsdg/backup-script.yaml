kind: ConfigMap
apiVersion: v1
metadata:
  name: baza-zespolsdg-backup-script
data:
  backup.sh: |-
    #! /bin/bash
    set -e

    echo "Starting backup script, installing dependencies..."
    apt update && apt-get -y install s3cmd ca-certificates gettext-base curl
    curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl
    cp kubectl /bin
    chmod +x /bin/kubectl

    echo "Shutting down NextCloud..."
    kubectl scale deployment baza-zespolsdg --replicas=0
    sleep 60

    BACKUP_ARCHIVE="/tmp/baza-zespolsdg-$(date +'%Y_%m_%d_%I_%M_%p').tar.bz2"
    SOURCE_DIR="/source"
    TARGET_BUCKET="s3://baza-zespolsdg-backups/"

    echo "Packing up ${SOURCE_DIR} into ${BACKUP_ARCHIVE}..."
    tar cpjf ${BACKUP_ARCHIVE} ${SOURCE_DIR}
    ls -l ${BACKUP_ARCHIVE}

    echo "Preparing s3cmd configuration..."
    envsubst < /backup-script/s3cfg.template > /tmp/s3cfg
    echo "Pushing backup into S3..."
    s3cmd --config=/tmp/s3cfg put --recursive --storage-class=STANDARD_IA ${BACKUP_ARCHIVE} ${TARGET_BUCKET}
    echo "Finished."

    echo "Removing archive to save space..."
    rm ${BACKUP_ARCHIVE}

    echo "Starting up NextCloud again..."
    kubectl scale deployment baza-zespolsdg --replicas=1

    echo "All done."
    exit 0

  s3cfg.template: |-
    [default]
    access_key = ${AWS_ACCESS_KEY}
    access_token =
    add_encoding_exts =
    add_headers =
    bucket_location = eu-central-1
    ca_certs_file =
    cache_file =
    check_ssl_certificate = True
    check_ssl_hostname = True
    cloudfront_host = cloudfront.amazonaws.com
    default_mime_type = binary/octet-stream
    delay_updates = False
    delete_after = False
    delete_after_fetch = False
    delete_removed = False
    dry_run = False
    enable_multipart = True
    encoding = UTF-8
    encrypt = False
    expiry_date =
    expiry_days =
    expiry_prefix =
    follow_symlinks = False
    force = False
    get_continue = False
    gpg_command = /usr/bin/gpg
    gpg_decrypt = %(gpg_command)s -d --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s
    gpg_encrypt = %(gpg_command)s -c --verbose --no-use-agent --batch --yes --passphrase-fd %(passphrase_fd)s -o %(output_file)s %(input_file)s
    gpg_passphrase =
    guess_mime_type = True
    host_base = s3.amazonaws.com
    host_bucket = %(bucket)s.s3.amazonaws.com
    human_readable_sizes = False
    invalidate_default_index_on_cf = False
    invalidate_default_index_root_on_cf = True
    invalidate_on_cf = False
    kms_key =
    limit = -1
    limitrate = 0
    list_md5 = False
    log_target_prefix =
    long_listing = False
    max_delete = -1
    mime_type =
    multipart_chunk_size_mb = 15
    multipart_max_chunks = 10000
    preserve_attrs = True
    progress_meter = True
    proxy_host =
    proxy_port = 0
    put_continue = False
    recursive = False
    recv_chunk = 65536
    reduced_redundancy = False
    requester_pays = False
    restore_days = 1
    restore_priority = Standard
    secret_key = ${AWS_SECRET_KEY}
    send_chunk = 65536
    server_side_encryption = False
    signature_v2 = False
    signurl_use_https = False
    simpledb_host = sdb.amazonaws.com
    skip_existing = False
    socket_timeout = 300
    stats = False
    stop_on_error = False
    storage_class =
    urlencoding_mode = normal
    use_http_expect = False
    use_https = True
    use_mime_magic = True
    verbosity = WARNING
    website_endpoint = http://%(bucket)s.s3-website-%(location)s.amazonaws.com/
    website_error =
    website_index = index.html

